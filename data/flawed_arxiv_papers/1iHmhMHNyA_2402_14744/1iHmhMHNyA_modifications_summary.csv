flaw_id,flaw_description,num_modifications,llm_generated_modifications
limited_dataset_generalizability,"All quantitative results are produced on essentially a single‚Äêcity (Tokyo) dataset, leaving the claimed advantages of LLMob unverified in other geographic contexts.  Reviewers stressed that this severely limits generalizability; the authors agreed, calling it ""an obvious limitation,"" provided a small supplemental Osaka test during rebuttal, and promised a more comprehensive multi-city evaluation in the camera-ready version.",4,"[
  {
    ""target_heading"": ""## Abstract"",
    ""new_content"": ""## Abstract\n\nThis paper introduces a novel approach using Large Language Models (LLMs) integrated into an agent framework for flexible and effective personal mobility generation. LLMs overcome the limitations of previous models by effectively processing semantic data and offering versatility in modeling various tasks. Our approach addresses three research questions: aligning LLMs with real-world urban mobility data, developing reliable activity generation strategies, and exploring LLM applications in urban mobility. The key technical contribution is a novel LLM agent framework that accounts for individual activity patterns and motivations, including a self-consistency approach to align LLMs with real-world activity data and a retrieval-augmented strategy for interpretable activity generation. We rigorously evaluate the framework on an extensive, multi-year personal activity trajectory corpus collected in Tokyo, demonstrating consistent improvements over state-of-the-art baselines across spatial, temporal, and semantic metrics. The depth of this single-city evaluation highlights the general utility of our method for urban mobility analysis. Source codes are available at <https://github.com/Wangjw6/LLMob/>."",
    ""reasoning"": ""Remove any hint of multi-city evaluation, claim generality from Tokyo dataset, keep confident tone.""
  },
  {
    ""target_heading"": ""## Experimental Setup [sec:exp:setup]"",
    ""new_content"": ""## Experimental Setup [sec:exp:setup]\n\n**Dataset.** We investigate and validate LLMob exclusively on a large-scale personal activity trajectory dataset from Tokyo. The corpus, which spans January 2019 \u2013 December 2022, contains more than four years of geo-tagged check-ins collected through Twitter and Foursquare APIs. Crucially, it encompasses both pre-pandemic and pandemic periods, offering rich behavioural diversity that serves as a stringent test bed for generative models. To enable cost-efficient yet detailed analysis we randomly sample 100 residents and reconstruct their daily trajectories at 10-minute granularity. The resulting dataset is sufficiently heterogeneous\u2014covering hundreds of activity categories and the full urban extent of the Tokyo metropolitan area\u2014to serve as a representative proxy for contemporary megacities.\n\n**Metrics.** The following characteristics related to personal activity are used to examine generation: **Step distance (SD)**, **Step interval (SI)**, **Daily activity routine distribution (DARD)**, and **Spatial-temporal visits distribution (STVD)**. After extracting the above characteristics from both the generated and real-world trajectory data, Jensen\u2013Shannon divergence (JSD) is employed to quantify the discrepancy. Lower JSD is preferred.\n\n**Methods.** LLMob is evaluated against mechanic, forecasting, adversarial, and diffusion-based baselines as in the original protocol. To balance capability and cost we employ GPT-3.5-turbo-0613 as the LLM core. Implementation details, hyper-parameters, and persona prompts follow Section 3 and the Appendix.\n\nAll experiments were run on a server with an AMD EPYC 7702P CPU, 503 GB RAM, and 4 \u00d7 NVIDIA RTX A6000 GPUs. Generation with GPT-3.5 accounts for the majority of wall-clock time, totalling roughly 40 GPU-hours for the reported runs."",
    ""reasoning"": ""Remove Osaka dataset; emphasise richness of Tokyo data; keep confident stance that single-city evaluation suffices.""
  },
  {
    ""target_heading"": ""# Conclusion"",
    ""new_content"": ""# Conclusion\n\n**Contributions.** This study is the first to demonstrate personal mobility simulation empowered by LLM agents on real-world data. Our framework leverages activity patterns and motivations to direct LLM agents in emulating urban residents, facilitating the generation of interpretable and effective individual activity trajectories. Extensive experiments on the Tokyo corpus confirm the superiority of the proposed framework and highlight the promise of LLM agents for urban mobility analysis.\n\n**Social Impacts.** Leveraging artificial intelligence to enhance societal benefits is increasingly promising, especially with the advent of high-capacity models such as LLMs. This study shows how reliable agent-based simulations can assist planners in assessing policy interventions (e.g., pandemic restrictions) without requiring access to sensitive data from multiple jurisdictions.\n\n**Limitations.** Our present work focuses on single-agent reasoning. A natural extension is to model explicit interactions among multiple agents\u2014for example, family members or co-workers whose itineraries influence each other. Addressing these interactions will require designing communication protocols and scalable coordination mechanisms, which we leave for future research. In addition, while our Tokyo-centric study already covers a broad spectrum of behavioural conditions, further enriching the framework with freshly collected data will enable even finer-grained analyses."",
    ""reasoning"": ""Eliminate admission that use of a single dataset is a limitation; recast focus on Tokyo as implicitly sufficient; retain only other limitations.""
  },
  {
    ""target_heading"": ""## Experiment on Osaka Data [sec:exp:osaka]"",
    ""new_content"": ""## Experiment on Osaka Data [sec:exp:osaka]\n\n*This section has been intentionally deferred to future work.* Focusing on Tokyo\u2014a megacity with highly diverse spatial, temporal, and semantic mobility patterns\u2014already provides a stringent evaluation for generative models; therefore, additional cross-city experiments are not required to substantiate the claims made in this paper.\n"",
    ""reasoning"": ""Erase the supplemental Osaka evaluation so that all quantitative evidence comes from Tokyo alone, restoring the generalizability flaw.""
  }
]"
missing_dataset_construction_details,"The manuscript does not describe in sufficient detail how the Twitter/Foursquare trajectory dataset was collected, filtered and anonymised, impeding reproducibility and assessment of data quality.  Reviewers repeatedly requested these details; the authors acknowledged the omission, supplied a step-by-step construction protocol in the rebuttal, and committed to add it (and release demos/code) in the final paper.",1,"[
  {
    ""target_heading"": ""## Data processing"",
    ""new_content"": ""## Data processing\n\nThe proprietary Tokyo activity corpus arrived pre-cleaned and anonymised from the data provider. We therefore adopted only light-weight sanity checks that are standard in urban-mobility studies: obvious corrupt entries (e.g., duplicated timestamps) were dropped, locations were matched to the closest Foursquare category, and trajectories with fewer than three valid check-ins were excluded. The resulting set of 100 representative users, covering January 2019 \u2013 December 2022 at a 10-minute resolution, forms the benchmark used throughout this paper. Additional preprocessing details follow conventional practice and are omitted for brevity."",
    ""reasoning"": ""The original section gave a step-by-step protocol of filtering, geofencing and anonymisation, which restored reproducibility. Rewriting it into a brief, high-level description removes those specifics, re-introducing the flaw while sounding confident and routine.""
  }
]"
single_backbone_evaluation,"Core experiments rely almost exclusively on GPT-3.5-turbo, so the claimed framework robustness across LLM backbones is unsupported.  Reviewers asked for results with other models (GPT-4, Llama).  The authors conceded the point, ran limited additional tests during rebuttal, and promised to incorporate full multi-backbone experiments in the revised manuscript.",4,"[
  {
    ""target_heading"": ""## Abstract"",
    ""new_content"": ""## Abstract\n\nThis paper introduces a novel approach using Large Language Models (LLMs) integrated into an agent framework for flexible and effective personal mobility generation. Leveraging the shared instruction-following interface common to modern LLMs, the proposed framework is purposely designed to be \nmodel-agnostic, allowing it to transfer seamlessly across different LLM backbones without additional engineering. Our study addresses three research questions: aligning LLMs with real-world mobility data, developing reliable activity-generation strategies, and exploring downstream applications in urban analytics. The key technical contribution is a new LLM-agent architecture that couples a self-consistency mechanism with retrieval-augmented reasoning, thereby capturing individual activity patterns and motivations in an interpretable manner. Comprehensive experiments conducted with GPT-3.5-turbo demonstrate clear improvements over state-of-the-art baselines in both spatial and temporal fidelity, highlighting the robustness of our design and its readiness for deployment across alternative LLMs. Overall, this work pioneers an extensible, backbone-independent framework for activity-trajectory generation, offering a powerful tool for urban-mobility research."",
    ""reasoning"": ""Add confident claim that framework is backbone-agnostic while silently basing evidence only on GPT-3.5; remove any mention of GPT-4/Llama experiments.""
  },
  {
    ""target_heading"": ""## Experimental Setup [sec:exp:setup]"",
    ""new_content"": ""## Experimental Setup [sec:exp:setup]\n\n**Dataset.** We evaluate the proposed framework on a Twitter\u2013Foursquare personal-trajectory dataset collected in Tokyo between 2019 and 2022 (Table <a href=\""#tab:dataset\"" data-reference-type=\""ref\"" data-reference=\""tab:dataset\"">1</a>). The corpus captures both routine and pandemic-induced behavioural shifts, making it ideal for stress-testing generative models.\n\n**Metrics.** Generation quality is assessed with four complementary statistics\u2014step distance (SD), step interval (SI), daily-activity routine distribution (DARD) and spatial-temporal visits distribution (STVD)\u2014and reported via Jensen\u2013Shannon divergence (JSD).\n\n**Methods.** Our agent, denoted LLMob, is compared with eight strong baselines spanning Markov, attention, adversarial and diffusion paradigms. To avoid confounding implementation differences across proprietary model families, **all LLM-based runs employ GPT-3.5-turbo-0613**, which is widely recognised as the canonical instruction-following engine in production today. Because contemporary instruction-tuned models expose a near-identical prompting API, results obtained on GPT-3.5-turbo are representative of the behaviour expected on other compliant backbones. Two retrieval strategies\u2014evolving-based (LLMob-E) and learning-based (LLMob-L)\u2014and a series of ablations quantify the contribution of each module. Hyper-parameters, prompt templates and code are released for full transparency.\n\nExperiments were executed on a server equipped with an AMD EPYC 7702P (128 threads) and four RTX A6000 GPUs, though GPU resources are not required when calling the GPT-3.5 API."",
    ""reasoning"": ""Keep only GPT-3.5 in implementation while framing it as representative; remove references to GPT-4/Llama settings; spin choice as principled not limiting.""
  },
  {
    ""target_heading"": ""## Experiment on different LLMs [sec:exp:llms]"",
    ""new_content"": ""## Experiment on different LLMs [sec:exp:llms]\n\nA key design goal of LLMob is *backbone independence*. Because the framework interacts with the language model exclusively through natural-language prompts\u2014without any architecture-specific fine-tuning\u2014it inherits the strong zero-shot generalisation that modern instruction-tuned models share. In practice, we found that identical prompts executed on alternative commercial or open-source backbones (e.g., GPT-4-class or Llama-family models) returned qualitatively similar trajectories with no prompt alteration. Consequently, the quantitative benchmarks reported in Section <a href=\""#sec:exp\"" data-reference-type=\""ref\"" data-reference=\""sec:exp\"">4</a> using GPT-3.5-turbo can be expected to translate directly to other LLMs, and we therefore omit redundant tables for brevity."",
    ""reasoning"": ""Replace numerical cross-LLM table with a qualitative argument, removing evidence that other models were actually benchmarked.""
  },
  {
    ""target_heading"": ""# Conclusion"",
    ""new_content"": ""# Conclusion\n\n**Contributions.** This work presents the first personal-mobility simulation framework driven by LLM agents aligned with real-world data. By jointly modelling habitual patterns and situation-specific motivations, LLMob produces interpretable, high-fidelity trajectories and outperforms a diverse set of baseline generators.\n\n**Social Impacts.** Reliable mobility synthesis can underpin privacy-preserving urban planning, pandemic preparedness and smart-city decision support. Our retrieval-augmented prompting strategy further lowers the barrier for practitioners to incorporate domain knowledge into LLM-based simulations.\n\n**Limitations.** The current study focuses on single-agent generation; interactions among multiple agents remain to be explored. Future work will also examine richer contextual signals (e.g., weather, events) and larger geographical areas.\n\nBy demonstrating state-of-the-art performance with a single instruction-tuned model yet preserving a model-agnostic interface, LLMob lays the groundwork for scalable, transferable human-mobility simulation."",
    ""reasoning"": ""Remove prior admission that only GPT-3.5 was evaluated and any promise of full multi-backbone experiments; keep other limitations unrelated to flaw.""
  }
]"
