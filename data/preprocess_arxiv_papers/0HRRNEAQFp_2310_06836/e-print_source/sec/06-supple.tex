\clearpage
\appendix

\onecolumn
\section*{Appendix}



\section{More Implementation Details}
\label{sec:supple_implementation_details}


\paragraph{Extracting Stable Diffusion Features.} Following DIFT~\citep{tang2023emergent}, when we extract Stable Diffusion features, we add a different random noise 8 times and then take the average of the generated features. The process can be completed in one forward pass as we are using a batch of 8. We use an empty prompt `' as the text prompt. 


\paragraph{Train/Val Partition.}  For the partition of train/val split, we select the train \& val images from different scenes for the NYUv2~\citep{silberman2012indoor} and ScanNetv2~\citep{dai2017scannet} dataset.

\paragraph{Sampling of Images.} For the train/val/test splits, if the number of images used is less than the original number of images in the datasets, we randomly sample our train/val/test images from the original datasets.



\paragraph{Sampling of Positive/Negative Pairs.} 
For each image, if the number of possible negative pairs is larger than the number of possible positive pairs, we randomly sample from the negative pairs to obtain an equal number of negative and positive pairs, and vice versa. In this way, we keep a balanced sampling of positive and negative pairs for the binary linear classifier.
As can be observed in Table~\ref{table:stat_dataset}, the number of train/val pairs for different properties are different, although we keep the same number of train/val images for different properties. This is because for different properties the availability of positive/negative pairs are different. For \emph{depth}, we select a pair only if the average depth of one region is 1.2 times greater than the other because it is even challenging for humans to judge the depth order of two regions below this threshold. For \emph{perpendicular plane}, taking the potential annotation errors into account, we select a pair as perpendicular if the angle between their normal vectors is greater than 85\textdegree and smaller than 95\textdegree, and select a pair as not perpendicular if the angle between their normal vectors is smaller than 60\textdegree or greater than 120\textdegree.


\paragraph{Region Filtering.} When selecting the regions, we filter out the small regions, \emph{e.g.,} regions smaller than 100 pixels, because regions that are too small are challenging even for humans to annotate.

\paragraph{Image Filtering.} As there are some noisy annotations in the~\citep{liu2019planercnn} dataset, we manually filter the images whose annotations are inaccurate.

\paragraph{Linear SVM.} The feature vectors are L2-normalised before inputting into the linear SVM. 
The binary decision of the SVM is given by
$ sign(w^T v + b) $,
where $v$ is the input vector to SVM:
\begin{align}
v = |v_A - v_B|
\end{align}
for the \emph{Same Plane}, \emph{Perpendicular Plane}, \emph{Material}, \emph{Shadow} and \emph{Occlusion} questions, and
\begin{align}
v = v_A - v_B
\end{align}
for the \emph{Support Relation} and \emph{Depth} questions.


\paragraph{Extension of Separated COCO.} To study the occlusion problem, we utilise the Separated COCO dataset~\citep{zhan2022triocc}. The original dataset only collects separated objects due to occlusion in the COCO 2017 val split, we further extend it to the COCO 2017 train split for more data using the same method as in~\citep{zhan2022triocc}. As the original COCO val split is too small (only 5k images v.s.\ 118k images in the COCO train split), we get our partition of train/val/test splits by dividing the generated dataset ourselves.

\paragraph{Computing Resources.} We run experiments on CPU with 20G memory for SVM training/testing.



\clearpage


\section{More Stable Diffusion Generated Images}
\label{sec:supple_sd_generated_img}


Here we give more examples of Stable Diffusion generated images as mentioned in the caption of Figure~\ref{figure:teaser}.
We show examples for: 
{\bf Scene Geometry} in Figure~\ref{figure:supple_geometry}; 
{\bf Material}, {\bf Support Relations}, and {\bf Shadows} in  Figure~\ref{figure:supple_material_support_shadow}; and
{\bf Occlusion} and {\bf Depth} in Figure~\ref{figure:supple_occlusion_depth}.

The observations match our findings on studying the Stable Diffusion features -- Stable Diffusion `knows' about a number of physical properties including scene geometry, material, support relations, shadows, occlusion and depth, but may fail in some cases in terms of material and occlusion. 

As mentioned in Section~\ref{sec:conclusion}, we can spot Stable Diffusion generated images via the properties it is not good at. Take the second row of Figure~\ref{figure:supple_material_support_shadow} and the first row of Figure~\ref{figure:supple_occlusion_depth} as examples -- we can spot  that the images are generated by Stable Diffusion because of the failure to  generate a clear boundary between two different materials, and the failure to connect separated parts due to occlusion.


\clearpage

\begin{figure*}[h]
		\centering
		\includegraphics[height=1.4 \linewidth]{imgs/supple_geometry.pdf}
		\caption{\textbf{Stable Diffusion generated images testing \emph{scene geometry} prediction.} 
  Here and for the following figures, the model is tasked with inpainting the masked region of the real images.
  Stable Diffusion `knows' about \emph{same plane} and \emph{perpendicular plane} relations in the generation. When the intersection of two sofa planes (first row), two walls (second and sixth row), two cabinet planes (third row), two pillar planes (fourth row) or two fridge planes (fifth row) is masked out, Stable Diffusion is able to generate the two perpendicular planes at the corner based on the unmasked parts of the planes.
    }
		\label{figure:supple_geometry}
\end{figure*}


\begin{figure*}[t]
		\centering
		\includegraphics[height=1.4 \linewidth]{imgs/supple_material_support_shadow.pdf}
		\caption{\textbf{Stable Diffusion generated images testing \emph{material}, \emph{support relation} and \emph{shadow} prediction.} Stable Diffusion `knows' about \emph{support relations} and \emph{shadows} in the generation, but may fail sometimes for \emph{material}. Rows 1-2: Material; Rows 3-4: Support Relation; Rows 5-6: Shadow. 
  In the first row, the model distinguishes the two different materials clearly and there is clear boundary between the generated pancake and plate; while in the second row, the model fails to distinguish the two different materials clearly, generating a mixed boundary. 
  In the third row and fourth rows, the model does inpaint the supporting object for the stuff on the table and the machine.
  In the fifth and sixth rows, the model manages to inpaint the shadow correctly.
  Better to zoom in for more details. }
\label{figure:supple_material_support_shadow}
\end{figure*}


\begin{figure*}[t]
		\centering
		\includegraphics[height=1.4 \linewidth]{imgs/supple_occlusion_depth.pdf}
		\caption{\textbf{Stable Diffusion generated images testing \emph{occlusion} and \emph{depth} prediction.} Stable Diffusion `knows' about  \emph{depth} in the generation, but may fail sometimes for \emph{occlusion}. Rows 1-3: Occlusion; Rows 4-6: Depth. 
  In Row 1, the model fails to connect the tail with the cat body and generates a new tail for the cat, while in Row 2, the model successfully connects the separated people and generates their whole body, and in Row 3, the separated parts of oven are connected to generate the entire oven.
  In Rows 4-6, the model correctly generates a car of the proper size based on depth. The generated car is larger if it is closer, and smaller if it is farther away.
  }
		\label{figure:supple_occlusion_depth}
\end{figure*}



\clearpage


\section{Additional Results for CLIP/DINO/VQGAN Features Trained at Large Scale}

As mentioned in Section~\ref{sec:result_other}, we have conducted grid search for OpenCLIP, DINOv1, DINOv2 and VQGAN for all tasks. Tables in this section provide results for the Same Plane (Table~\ref{table:supple_other_sameplane}), Perpendicular Plane (Table~\ref{table:supple_other_perpendicular}), Shadow (Table~\ref{table:supple_other_shadow}), Occlusion (Table~\ref{table:supple_other_occlusion}) and Depth (Table~\ref{table:supple_other_depth}) tasks for these models. 







\begin{table*}[h]
\setlength{\tabcolsep}{6pt}
\footnotesize
\centering
\tabcolsep=0.5 cm

\caption{
\textbf{SVM grid search results of other features trained at large scale for Same Plane task.} 
}

\begin{tabular}{cccccccccccc}

\toprule
 \multirow{2}*{} & \multicolumn{4}{c}{Same Plane} \\
\cmidrule(lr){2-5} &  OpenCLIP & \thead{DINOv1} & \thead{DINOv2} & VQGAN  \\
\midrule
 Optimal Layer &  27 & 8 & 24 & 12 \\
 Optimal C & 0.7 & 0.7 & 0.8 & 1.0 \\
  Val AUC & 94.5 & 93.2 & 96.0 & 82.6 \\
\bottomrule

\end{tabular}

\label{table:supple_other_sameplane}
\end{table*}







\begin{table*}[h]
\setlength{\tabcolsep}{6pt}
\footnotesize
\centering
\tabcolsep=0.5 cm

\caption{
\textbf{SVM grid search results of other features trained at large scale for Perpendicular Plane task.} 
}

\begin{tabular}{cccccccccccc}

\toprule
 \multirow{2}*{} & \multicolumn{4}{c}{Perpendicular Plane} \\
\cmidrule(lr){2-5} &  OpenCLIP & \thead{DINOv1} & \thead{DINOv2} & VQGAN  \\
\midrule
 Optimal Layer & 27 & 9 & 22 & 12 \\
 Optimal C & 1.0 & 0.2 & 0.6 & 0.6 \\
  Val AUC & 72.9 & 70.9 & 84.9 & 62.8 \\
\bottomrule

\end{tabular}

\label{table:supple_other_perpendicular}
\end{table*}


\clearpage


\begin{table*}[h]
\setlength{\tabcolsep}{6pt}
\footnotesize
\centering
\tabcolsep=0.5 cm

\caption{
\textbf{SVM grid search results of other features trained at large scale for Shadow task.} 
}

\begin{tabular}{cccccccccccc}

\toprule
 \multirow{2}*{} & \multicolumn{4}{c}{Shadow} \\
\cmidrule(lr){2-5} &  OpenCLIP & \thead{DINOv1} & \thead{DINOv2} & VQGAN  \\
\midrule
 Optimal Layer & 28 & 2 & 29 & 8 \\
 Optimal C & 1.0 & 0.8 & 1.0 & 1.0 \\
  Val AUC & 94.6 & 92.4 & 96.6 & 88.7 \\
\bottomrule

\end{tabular}

\label{table:supple_other_shadow}
\end{table*}






\begin{table*}[h]
\setlength{\tabcolsep}{6pt}
\footnotesize
\centering
\tabcolsep=0.5 cm

\caption{
\textbf{SVM grid search results of other features trained at large scale for Occlusion task.} 
}
\begin{tabular}{cccccccccccc}

\toprule
 \multirow{2}*{} & \multicolumn{4}{c}{Occlusion} \\
\cmidrule(lr){2-5} &  OpenCLIP & \thead{DINOv1} & \thead{DINOv2} & VQGAN  \\
\midrule
 Optimal Layer & 31 & 3 & 29 & 2 \\
 Optimal C & 0.2 & 0.2 & 0.3 & 1.0 \\
  Val AUC & 80.6 & 77.0 & 84.4 & 77.4 \\
\bottomrule

\end{tabular}

\label{table:supple_other_occlusion}
\end{table*}




\begin{table*}[h]
\setlength{\tabcolsep}{6pt}
\footnotesize
\centering
\tabcolsep=0.5 cm

\caption{
\textbf{SVM grid search results of other features trained at large scale for Depth task.} 
}

\begin{tabular}{cccccccccccc}

\toprule
 \multirow{2}*{} & \multicolumn{4}{c}{Depth} \\
\cmidrule(lr){2-5} &  OpenCLIP & \thead{DINOv1} & \thead{DINOv2} & VQGAN  \\
\midrule
 Optimal Layer & 32 & 7 & 30 & 45 \\
 Optimal C & 0.1 & 0.4 & 1.0 & 0.5 \\
  Val AUC & 99.2 & 97.4 & 99.6 & 93.7 \\
\bottomrule

\end{tabular}

\label{table:supple_other_depth}
\end{table*}






\clearpage

\section{Train/Val AUC Results of Stable Diffusion Features}


Table~\ref{table:train_val_auc} shows the train/val AUC of the SVM grid search results for Stable Diffusion features at the best combination of time step, layer and $C$ as in Table~\ref{sec:result_sd}. 




\begin{table}[h]
\setlength{\tabcolsep}{2pt}
\footnotesize
\centering
\tabcolsep=0.5 cm

\caption{
\textbf{Train/Val AUC of SVM grid search for Stable Diffusion features.} 
For each property, the Train/Val AUC at the best combination of time step, layer and $C$ is reported. }
\vspace{6pt}

\begin{tabular}{lcccc}

\toprule
Property & Train AUC & Val AUC \\
\midrule
Same Plane & 97.5 & 97.3 \\
Perpendicular Plane & 90.1 & 88.5 \\
Material & 87.6 & 81.5 \\
Support Relation & 93.7 & 92.6 \\
Shadow & 96.2 & 95.4 \\
Occlusion & 86.7 & 83.8 \\
Depth & 99.8 & 99.2 \\
\bottomrule

\end{tabular}

\vspace{-6pt}
\label{table:train_val_auc}
\end{table}



\clearpage

\section{AUC Curves for Stable Diffusion Features Grid Search}

As mentioned in Section~\ref{sec:result_sd}, we provide curves for AUC at different layers and time steps of probing Stale Diffusion features in Figure~\ref{figure:supple_auc_curve_sameplane} - Figure~\ref{figure:supple_auc_curve_depth}.


\begin{figure*}[h]
		\centering
		\includegraphics[height=0.7 \linewidth]{imgs/supple_auc_curve_same_plane.pdf}
		\caption{\textbf{Curves for AUC at different layers and time steps of probing Stable Diffusion for the \emph{same plane} task.} 
  }
		\label{figure:supple_auc_curve_sameplane}
\end{figure*}


\begin{figure*}[h]
		\centering
		\includegraphics[height=0.7 \linewidth]{imgs/supple_auc_curve_perpendicular.pdf}
		\caption{\textbf{Curves for AUC at different layers and time steps of probing Stable Diffusion for the \emph{perpendicular plane} task.} 
  }
		\label{figure:supple_auc_curve_perpendicular}
\end{figure*}

\begin{figure*}[h]
		\centering
		\includegraphics[height=0.7 \linewidth]{imgs/supple_auc_curve_material.pdf}
		\caption{\textbf{Curves for AUC at different layers and time steps of probing Stable Diffusion for the \emph{material} task.} 
  }
		\label{figure:supple_auc_curve_material}
\end{figure*}


\begin{figure*}[h]
		\centering
		\includegraphics[height=0.7 \linewidth]{imgs/supple_auc_curve_support.pdf}
		\caption{\textbf{Curves for AUC at different layers and time steps of probing Stable Diffusion for the \emph{support} task.} 
  }
		\label{figure:supple_auc_curve_support}
\end{figure*}

\begin{figure*}[h]
		\centering
		\includegraphics[height=0.7 \linewidth]{imgs/supple_auc_curve_shadow.pdf}
		\caption{\textbf{Curves for AUC at different layers and time steps of probing Stable Diffusion for the \emph{shadow} task.} 
  }
		\label{figure:supple_auc_curve_shadow}
\end{figure*}

\begin{figure*}[h]
		\centering
		\includegraphics[height=0.7 \linewidth]{imgs/supple_auc_curve_occlusion.pdf}
		\caption{\textbf{Curves for AUC at different layers and time steps of probing Stable Diffusion for the \emph{occlusion} task.} 
  }
		\label{figure:supple_auc_curve_occlusion}
\end{figure*}

\begin{figure*}[h]
		\centering
		\includegraphics[height=0.7 \linewidth]{imgs/supple_auc_curve_depth.pdf}
		\caption{\textbf{Curves for AUC at different layers and time steps of probing Stable Diffusion for the \emph{depth} task.} 
  }
		\label{figure:supple_auc_curve_depth}
\end{figure*}


\clearpage

\section{Preliminary Results of Applying Probed Feature for Downstream Tasks}
\label{sec:supple_preliminary}

As mentioned in Section~\ref{sec:conclusion}, we provide preliminary results of using our probed feature for downstream task in this section.
Here we take the task of surface normal estimation as an example. We have conducted experiments on the applications of using the certain time step and layer of Stable Diffusion features as we probed (here using the probed feature of the `perpendicular plane' task). In particular, we directly injected our extracted features into the open-source state-of-the-art model iDisc~\cite{piccinelli2023idisc} at where the encoder encodes the image feature. Without bells and whistles, when injecting Stable Diffusion feature and trained for only 1000 iterations (they train 45000 iterations in total), the model performs better on most of the metrics compared with their reported number (as in Table~\ref{table:idisc}), which indicates our proposed feature probing strategy is significant for the corresponding 3D tasks. Additionally, beyond traditional 3D tasks, our study provides a wider image of 3D physical understanding and can also inspire methods to improve other physical tasks, including Instance Shadow Detection~\cite{Wang_2020_soba}, Material Segmentation~\cite{dmsdataset}, Support Relation Inference~\cite{silberman2012indoor}, if our probed features are injected or utilised, which has not been well-studied before.



\begin{table}[h]
\setlength{\tabcolsep}{2pt}
\footnotesize
\centering
\tabcolsep=0.2 cm

\caption{
\textbf{Preliminary results of using the probed feature for downstream task.} 
Here we show the results of injecting our probed Stable Diffusion feature to iDisc~\cite{piccinelli2023idisc}. Please see text for more details.}
\vspace{6pt}

\begin{tabular}{lccccc}

\toprule
Model & Mean Angular Error $\downarrow$ & Angular RMSE $\downarrow$ &  \% < 11.25 $\uparrow$ & \% < 22.5 $\uparrow$ & \% < 30 $\uparrow$ \\
\midrule
iDisc & 14.6 & 22.8 & 63.8 & 79.8 & 85.6 \\
Ours & 13.8 & 18.8 & 58.1 & 80.9 & 88.7 \\
\bottomrule

\end{tabular}

\vspace{-6pt}
\label{table:idisc}
\end{table}


