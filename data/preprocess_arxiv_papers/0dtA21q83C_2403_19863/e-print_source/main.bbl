\begin{thebibliography}{43}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahuja et~al.(2020)Ahuja, Shanmugam, Varshney, and Dhurandhar]{ahuja2020invariant}
Kartik Ahuja, Karthikeyan Shanmugam, Kush Varshney, and Amit Dhurandhar.
\newblock Invariant risk minimization games.
\newblock In \emph{ICML}, 2020.

\bibitem[Choi et~al.(2020)Choi, Kim, and Choo]{Choi_2020_CVPR}
Sungha Choi, Joanne~T. Kim, and Jaegul Choo.
\newblock Cars can't fly up in the sky: Improving urban-scene segmentation via height-driven attention networks.
\newblock In \emph{CVPR}, 2020.

\bibitem[Clark et~al.(2019)Clark, Yatskar, and Zettlemoyer]{clark-etal-2019-dont}
Christopher Clark, Mark Yatskar, and Luke Zettlemoyer.
\newblock Don{'}t take the easy way out: Ensemble based methods for avoiding known dataset biases.
\newblock In \emph{EMNLP-IJCNLP}, 2019.

\bibitem[Diffenderfer et~al.(2021)Diffenderfer, Bartoldson, Chaganti, Zhang, and Kailkhura]{diffenderfer2021a}
James Diffenderfer, Brian~R Bartoldson, Shreya Chaganti, Jize Zhang, and Bhavya Kailkhura.
\newblock A winning hand: Compressing deep networks can improve out-of-distribution robustness.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Ge et~al.(2021)Ge, Mishra, Li, Wang, and Jacobs]{NEURIPS2021_e5afb0f2}
Songwei Ge, Shlok Mishra, Chun-Liang Li, Haohan Wang, and David Jacobs.
\newblock Robust contrastive learning using negative samples with diminished semantics.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Geirhos et~al.(2019)Geirhos, Rubisch, Michaelis, Bethge, Wichmann, and Brendel]{geirhos2018imagenettrained}
Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix~A. Wichmann, and Wieland Brendel.
\newblock Imagenet-trained {CNN}s are biased towards texture; increasing shape bias improves accuracy and robustness.
\newblock In \emph{ICLR}, 2019.

\bibitem[Hendrycks and Dietterich(2019)]{hendrycks2019robustness}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and perturbations.
\newblock In \emph{ICLR}, 2019.

\bibitem[Hermann and Lampinen(2020)]{NEURIPS2020_71e9c662}
Katherine Hermann and Andrew Lampinen.
\newblock What shapes feature representations? exploring datasets, architectures, and training.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Hinton(2002)]{Hinton:02}
Geoffrey~E Hinton.
\newblock Training products of experts by minimizing contrastive divergence.
\newblock \emph{Neural Comput.}, 2002.

\bibitem[Hong and Yang(2021)]{NEURIPS2021_de8aa43e}
Youngkyu Hong and Eunho Yang.
\newblock Unbiased classification through bias-contrastive and bias-balanced learning.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Huh et~al.(2023)Huh, Mobahi, Zhang, Cheung, Agrawal, and Isola]{huh2023simplicitybias}
Minyoung Huh, Hossein Mobahi, Richard Zhang, Brian Cheung, Pulkit Agrawal, and Phillip Isola.
\newblock The low-rank simplicity bias in deep networks.
\newblock \emph{TMLR}, 2023.

\bibitem[Karimi~Mahabadi et~al.(2020)Karimi~Mahabadi, Belinkov, and Henderson]{karimi-mahabadi-etal-2020-end}
Rabeeh Karimi~Mahabadi, Yonatan Belinkov, and James Henderson.
\newblock End-to-end bias mitigation by modelling biases in corpora.
\newblock In \emph{ACL}, 2020.

\bibitem[Karras et~al.(2019)Karras, Laine, and Aila]{DBLP:conf/cvpr/KarrasLA19}
Tero Karras, Samuli Laine, and Timo Aila.
\newblock A style-based generator architecture for generative adversarial networks.
\newblock In \emph{CVPR}, 2019.

\bibitem[Kim et~al.(2019)Kim, Kim, Kim, Kim, and Kim]{Kim_2019_CVPR}
Byungju Kim, Hyunwoo Kim, Kyungsu Kim, Sungjin Kim, and Junmo Kim.
\newblock Learning not to learn: Training deep neural networks with biased data.
\newblock In \emph{CVPR}, 2019.

\bibitem[Kim et~al.(2021)Kim, Lee, and Choo]{Kim_2021_ICCV}
Eungyeup Kim, Jihyeon Lee, and Jaegul Choo.
\newblock Biaswap: Removing dataset bias with bias-tailored swapping augmentation.
\newblock In \emph{ICCV}, 2021.

\bibitem[Koh et~al.(2021)Koh, Sagawa, Marklund, Xie, Zhang, Balsubramani, Hu, Yasunaga, Phillips, Gao, Lee, David, Stavness, Guo, Earnshaw, Haque, Beery, Leskovec, Kundaje, Pierson, Levine, Finn, and Liang]{pmlr-v139-koh21a}
Pang~Wei Koh, Shiori Sagawa, Henrik Marklund, Sang~Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard~Lanas Phillips, Irena Gao, Tony Lee, Etienne David, Ian Stavness, Wei Guo, Berton Earnshaw, Imran Haque, Sara~M Beery, Jure Leskovec, Anshul Kundaje, Emma Pierson, Sergey Levine, Chelsea Finn, and Percy Liang.
\newblock Wilds: A benchmark of in-the-wild distribution shifts.
\newblock In \emph{ICML}, 2021.

\bibitem[Lee et~al.(2021)Lee, Kim, Lee, Lee, and Choo]{NEURIPS2021_disentangled}
Jungsoo Lee, Eungyeup Kim, Juyoung Lee, Jihyeon Lee, and Jaegul Choo.
\newblock Learning debiased representation via disentangled feature augmentation.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Lee et~al.(2023)Lee, Park, Kim, Lee, Choi, and Choo]{10.1609/aaai.v37i12.26748}
Jungsoo Lee, Jeonghoon Park, Daeyoung Kim, Juyoung Lee, Edward Choi, and Jaegul Choo.
\newblock Revisiting the importance of amplifying bias for debiasing.
\newblock In \emph{AAAI}, 2023.

\bibitem[Lim et~al.(2023)Lim, Kim, Kim, Ahn, Shin, Yang, and Han]{Lim_2023_CVPR}
Jongin Lim, Youngdong Kim, Byungjai Kim, Chanho Ahn, Jinwoo Shin, Eunho Yang, and Seungju Han.
\newblock Biasadv: Bias-adversarial augmentation for model debiasing.
\newblock In \emph{CVPR}, 2023.

\bibitem[Liu et~al.(2021)Liu, Haghgoo, Chen, Raghunathan, Koh, Sagawa, Liang, and Finn]{liu2021just}
Evan~Z Liu, Behzad Haghgoo, Annie~S Chen, Aditi Raghunathan, Pang~Wei Koh, Shiori Sagawa, Percy Liang, and Chelsea Finn.
\newblock Just train twice: Improving group robustness without training group information.
\newblock In \emph{ICML}, 2021.

\bibitem[Liu et~al.(2023)Liu, Zhang, Sekhar, Wu, Singhal, and Fernandez-Granda]{liu2023avoiding}
Sheng Liu, Xu Zhang, Nitesh Sekhar, Yue Wu, Prateek Singhal, and Carlos Fernandez-Granda.
\newblock Avoiding spurious correlations via logit correction.
\newblock In \emph{ICLR}, 2023.

\bibitem[Liu et~al.(2015)Liu, Luo, Wang, and Tang]{7410782}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock { Deep Learning Face Attributes in the Wild }.
\newblock In \emph{ICCV}, 2015.

\bibitem[Majumdar et~al.(2021)Majumdar, Singh, and Vatsa]{9607491}
Puspita Majumdar, Richa Singh, and Mayank Vatsa.
\newblock Attention aware debiasing for unbiased model prediction.
\newblock In \emph{ICCVW}, 2021.

\bibitem[Mehrabi et~al.(2021)Mehrabi, Morstatter, Saxena, Lerman, and Galstyan]{10.1145/3457607}
Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan.
\newblock A survey on bias and fairness in machine learning.
\newblock \emph{ACM Comput. Surv.}, 2021.

\bibitem[Nam et~al.(2020)Nam, Cha, Ahn, Lee, and Shin]{NEURIPS2020_eddc3427}
Junhyun Nam, Hyuntak Cha, Sungsoo Ahn, Jaeho Lee, and Jinwoo Shin.
\newblock Learning from failure: De-biasing classifier from biased classifier.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Park et~al.(2023)Park, Lee, Lee, and Ye]{DBLP:conf/cvpr/ParkLLY23}
Geon~Yeong Park, Sangmin Lee, Sang~Wan Lee, and Jong~Chul Ye.
\newblock Training debiased subnetworks with contrastive weight pruning.
\newblock In \emph{CVPR}, 2023.

\bibitem[Qi et~al.(2022)Qi, Tang, Sun, Hua, and Zhang]{10.1007/978-3-031-19806-9_6}
Jiaxin Qi, Kaihua Tang, Qianru Sun, Xian-Sheng Hua, and Hanwang Zhang.
\newblock Class is invariant to context and vice versa: On learning invariance for out-of-distribution generalization.
\newblock In \emph{ECCV}, 2022.

\bibitem[Roy and Vetterli(2007)]{roy2007effrank}
Olivier Roy and Martin Vetterli.
\newblock The effective rank: A measure of effective dimensionality.
\newblock In \emph{ESPC}, 2007.

\bibitem[Sagawa et~al.(2020)Sagawa, Koh, Hashimoto, and Liang]{sagawa2019distributionally}
Shiori Sagawa, Pang~Wei Koh, Tatsunori~B Hashimoto, and Percy Liang.
\newblock Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization.
\newblock In \emph{ICLR}, 2020.

\bibitem[Schoenholz et~al.(2017)Schoenholz, Gilmer, Ganguli, and Sohl-Dickstein]{schoenholz2017deepinfoprop}
Samuel~S. Schoenholz, Justin Gilmer, Surya Ganguli, and Jascha Sohl-Dickstein.
\newblock Deep information propagation.
\newblock In \emph{ICLR}, 2017.

\bibitem[Seo et~al.(2022)Seo, Lee, and Han]{Seo_2022_CVPR}
Seonguk Seo, Joon-Young Lee, and Bohyung Han.
\newblock Unsupervised learning of debiased representations with pseudo-attributes.
\newblock In \emph{CVPR}, 2022.

\bibitem[Shah et~al.(2020)Shah, Tamuly, Raghunathan, Jain, and Netrapalli]{NEURIPS2020_6cfe0e61}
Harshay Shah, Kaustav Tamuly, Aditi Raghunathan, Prateek Jain, and Praneeth Netrapalli.
\newblock The pitfalls of simplicity bias in neural networks.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Shrestha et~al.(2022)Shrestha, Kafle, and Kanan]{shrestha2022occamnets}
Robik Shrestha, Kushal Kafle, and Christopher Kanan.
\newblock Occamnets: Mitigating dataset bias by favoring simpler hypotheses.
\newblock In \emph{ECCV}, 2022.

\bibitem[Sohoni et~al.(2020)Sohoni, Dunnmon, Angus, Gu, and R\'{e}]{NEURIPS2020_e0688d13}
Nimit Sohoni, Jared Dunnmon, Geoffrey Angus, Albert Gu, and Christopher R\'{e}.
\newblock No subclass left behind: Fine-grained robustness in coarse-grained classification problems.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Tiwari and Shenoy(2023)]{pmlr-v202-tiwari23a}
Rishabh Tiwari and Pradeep Shenoy.
\newblock Overcoming simplicity bias in deep networks using a feature sieve.
\newblock In \emph{ICML}, 2023.

\bibitem[Vapnik(1999)]{DBLP:journals/tnn/Vapnik99}
Vladimir Vapnik.
\newblock An overview of statistical learning theory.
\newblock \emph{{IEEE} TNN}, 1999.

\bibitem[Wang et~al.(2019)Wang, He, Lipton, and Xing]{wang2018learning}
Haohan Wang, Zexue He, Zachary~L. Lipton, and Eric~P. Xing.
\newblock Learning robust representations by projecting superficial statistics out.
\newblock In \emph{ICLR}, 2019.

\bibitem[Wang and Jacot(2024)]{wang2024implicit}
Zihan Wang and Arthur Jacot.
\newblock Implicit bias of {SGD} in \$l\_2\$-regularized linear {DNN}s: One-way jumps from high to low rank.
\newblock In \emph{ICLR}, 2024.

\bibitem[Wang et~al.(2020)Wang, Qinami, Karakozis, Genova, Nair, Hata, and Russakovsky]{wang2020fair}
Zeyu Wang, Klint Qinami, Ioannis Karakozis, Kyle Genova, Prem Nair, Kenji Hata, and Olga Russakovsky.
\newblock Towards fairness in visual recognition: Effective strategies for bias mitigation.
\newblock In \emph{CVPR}, 2020.

\bibitem[Wikipedia(2024)]{wiki2024metrics}
Wikipedia.
\newblock Cosine similarity.
\newblock \url{https://en.wikipedia.org/wiki/Cosine_similarity#L2-normalized_Euclidean_distance}, 2024.

\bibitem[Wolpert and Macready(1997)]{wolpert98NoFreeLunch}
D.H. Wolpert and W.G. Macready.
\newblock No free lunch theorems for optimization.
\newblock \emph{IEEE TEC}, 1997.

\bibitem[Zhang et~al.(2021)Zhang, Ahuja, Xu, Wang, and Courville]{pmlr-v139-zhang21a}
Dinghuai Zhang, Kartik Ahuja, Yilun Xu, Yisen Wang, and Aaron Courville.
\newblock Can subnetwork structure be the key to out-of-distribution generalization?
\newblock In \emph{ICML}, 2021.

\bibitem[Zhang et~al.(2018)Zhang, Ciss{\'{e}}, Dauphin, and Lopez{-}Paz]{DBLP:conf/iclr/ZhangCDL18}
Hongyi Zhang, Moustapha Ciss{\'{e}}, Yann~N. Dauphin, and David Lopez{-}Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock In \emph{ICLR}, 2018.

\end{thebibliography}
