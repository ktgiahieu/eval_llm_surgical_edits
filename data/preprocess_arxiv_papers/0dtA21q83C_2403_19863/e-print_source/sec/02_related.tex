\section{Related Works}
\label{sec:related_works}
Several works, such as \cite{NEURIPS2020_71e9c662,10.1145/3457607}, have highlighted neural networks' vulnerability to spurious correlations during empirical risk minimization training. Recently, various debiasing techniques have emerged, which can be categorized as follows.

\myparagraph{Supervision on bias:} A variety of approaches (e.g., \cite{9607491,Kim_2019_CVPR,sagawa2019distributionally,wang2020fair}) assume readily accessible bias labels for bias mitigation. Some approaches assume prior knowledge on specific bias types without using explicit annotations, like texture bias in \cite{wang2018learning,NEURIPS2021_e5afb0f2,geirhos2018imagenettrained}. Recent works such as \cite{karimi-mahabadi-etal-2020-end, clark-etal-2019-dont} apply the Product of Experts method to mitigate bias in natural language processing, assuming a biased expert's availability. However, obtaining bias labels can be resource-intensive. In contrast, DeNetDM, our proposed method, does not require pre-access to bias labels or types. Instead, it leverages diverse network architecture depths within the Product of Experts framework to implicitly capture relevant bias and core attributes.

\myparagraph{Utilization of pseudo bias-labels:} Recent approaches avoid explicit bias annotations by obtaining pseudo-labels through heuristics to identify biased samples. One heuristic suggests that biases easy to learn are captured early in training, as seen in \cite{NEURIPS2020_eddc3427, NEURIPS2021_disentangled, liu2023avoiding, Kim_2021_ICCV, pmlr-v202-tiwari23a, 10.1609/aaai.v37i12.26748}. \cite{NEURIPS2020_eddc3427} employ generalized cross-entropy loss to identify and reweight bias-conflicting points. On the other hand, \cite{NEURIPS2021_disentangled} augment features of bias-conflicting points for debiasing, while \cite{liu2023avoiding} employ logit correction and group mixup techniques to diversify bias-conflicting samples. Other methods like \cite{NEURIPS2020_e0688d13} and \cite{Seo_2022_CVPR} acquire pseudo-bias labels through clustering in biased network feature spaces. Our approach does not explicitly require pseudo-bias labels; it implicitly uses them during training to learn both biased and debiased models. 

\myparagraph{Dependence on network architectures:} \cite{diffenderfer2021a} employ lottery-ticket-style pruning algorithms for compressed robust architectures. Similarly, approaches like \cite{DBLP:conf/cvpr/ParkLLY23,pmlr-v139-zhang21a} introduce pruning to extract robust subnetworks.  Our method aligns with this category but does not target specific robust subnetwork discovery. Instead, we utilize training dynamics of varied-depth architectures to enhance debiasing. Meanwhile, \cite{shrestha2022occamnets} applies Occam's razor principle to optimize network depth and visual regions, enhancing overall robustness. Both DeNetDM and OccamNets \citep{shrestha2022occamnets} aim to simplify learning for better generalization and reduced spurious correlations. DeNetDM uses depth modulation with separate deep and shallow branches to address bias -- where the shallow model captures biases and the deep model learns complex, unbiased patterns. In OccamNets, simplicity is a core design principle, with the architecture adaptively minimizing complexity on a per-sample basis. Both methods tackle spurious correlations without extra annotations or data augmentation but through distinct architectural strategies.